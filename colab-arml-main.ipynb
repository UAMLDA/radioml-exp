{"cells":[{"cell_type":"markdown","metadata":{"id":"0jJG06bS16dE"},"source":["# Google Colab Main Document \n","\n","This notebook is the main runs the main experiments for adverasrial attacks against the [RadioML](https://www.deepsig.ai/datasets) dataset. It is recommended that a GPU is used to run the code to reduce the amount of time it takes to generate the results. \n","\n","The environment requires the [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox) which is installed in this document. If you're running this code on a cloud node or a personal machine then you need to make sure this package is installed along with the other dependencies. One other note to take into account is that this notebook is only designed to run on Google Colab because it connects to my Google Drive. \n"],"id":"0jJG06bS16dE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAxqNThB1ymJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive') "],"id":"BAxqNThB1ymJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"lj7In9chz716"},"outputs":[],"source":["%cd /content/gdrive/MyDrive/Git/adversarial-radioml/"],"id":"lj7In9chz716"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhwQ-u342M79"},"outputs":[],"source":["!pip install -r requirements.txt"],"id":"WhwQ-u342M79"},{"cell_type":"markdown","metadata":{"id":"S4i37i1V2W02"},"source":["# Experiments \n","\n","- `test_exp_fgsm.py`: This script runs an experiment that evaluates different values of epsilon in the Fast Gradient Sign Method attack. The values for epsilon are `[0.01, 0.025, 0.5, ..., 0.2]`. The output is saved in a pickle file in `outputs/`\n","- `test_exp_multiple_attacks.py`: This script runs an experiment that generated adversarial data using FGSM, PGD and DeepFool. The output is saved in a pickle file in `outputs/`. This script is very time consuming and it is recommended that a TPU is used to accelerate the training time. "],"id":"S4i37i1V2W02"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukNlHMJz2RVC"},"outputs":[],"source":["!python test_exp_fgsm.py"],"id":"ukNlHMJz2RVC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Vi339os_IcL"},"outputs":[],"source":["!python test_exp_deepfool.py"],"id":"7Vi339os_IcL"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2979541,"status":"ok","timestamp":1650502927728,"user":{"displayName":"Megan C Giffee-Herzog","userId":"18124054058303813209"},"user_tz":420},"id":"LHSK1Chx_K_D","outputId":"2efd4c0a-8071-4373-801c-3f1d2d46f5be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current defense: None\n","\n","Train on 158400 samples, validate on 17600 samples\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n","Epoch 1/50\n","2022-04-20 22:19:04.741353: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","158400/158400 [==============================] - 117s 740us/sample - loss: 2.2031 - val_loss: 1.9341\n","Epoch 2/50\n","158400/158400 [==============================] - 100s 631us/sample - loss: 1.8981 - val_loss: 1.7554\n","Epoch 3/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.6974 - val_loss: 1.5373\n","Epoch 4/50\n","158400/158400 [==============================] - 100s 632us/sample - loss: 1.5811 - val_loss: 1.4765\n","Epoch 5/50\n","158400/158400 [==============================] - 100s 634us/sample - loss: 1.5127 - val_loss: 1.4083\n","Epoch 6/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.4331 - val_loss: 1.3345\n","Epoch 7/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.3834 - val_loss: 1.2874\n","Epoch 8/50\n","158400/158400 [==============================] - 100s 634us/sample - loss: 1.3595 - val_loss: 1.2735\n","Epoch 9/50\n","158400/158400 [==============================] - 99s 622us/sample - loss: 1.3446 - val_loss: 1.2760\n","Epoch 10/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.3305 - val_loss: 1.2440\n","Epoch 11/50\n","158400/158400 [==============================] - 98s 617us/sample - loss: 1.3231 - val_loss: 1.2803\n","Epoch 12/50\n","158400/158400 [==============================] - 100s 633us/sample - loss: 1.3112 - val_loss: 1.2321\n","Epoch 13/50\n","158400/158400 [==============================] - 101s 638us/sample - loss: 1.2951 - val_loss: 1.2279\n","Epoch 14/50\n","158400/158400 [==============================] - 98s 620us/sample - loss: 1.2889 - val_loss: 1.2444\n","Epoch 15/50\n","158400/158400 [==============================] - 98s 619us/sample - loss: 1.2829 - val_loss: 1.2289\n","Epoch 16/50\n","158400/158400 [==============================] - 100s 631us/sample - loss: 1.2738 - val_loss: 1.2088\n","Epoch 17/50\n","158400/158400 [==============================] - 98s 618us/sample - loss: 1.2629 - val_loss: 1.2628\n","Epoch 18/50\n","158400/158400 [==============================] - 100s 628us/sample - loss: 1.2640 - val_loss: 1.2008\n","Epoch 19/50\n","158400/158400 [==============================] - 98s 617us/sample - loss: 1.2511 - val_loss: 1.2218\n","Epoch 20/50\n","158400/158400 [==============================] - 100s 634us/sample - loss: 1.2408 - val_loss: 1.1980\n","Epoch 21/50\n","158400/158400 [==============================] - 101s 637us/sample - loss: 1.2334 - val_loss: 1.1781\n","Epoch 22/50\n","158400/158400 [==============================] - 101s 637us/sample - loss: 1.2235 - val_loss: 1.1733\n","Epoch 23/50\n","158400/158400 [==============================] - 100s 632us/sample - loss: 1.2113 - val_loss: 1.1581\n","Epoch 24/50\n","158400/158400 [==============================] - 99s 628us/sample - loss: 1.2112 - val_loss: 1.1723\n","Epoch 25/50\n","158400/158400 [==============================] - 98s 621us/sample - loss: 1.1936 - val_loss: 1.1584\n","Epoch 26/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.1851 - val_loss: 1.1431\n","Epoch 27/50\n","158400/158400 [==============================] - 97s 610us/sample - loss: 1.1777 - val_loss: 1.1661\n","Epoch 28/50\n","158400/158400 [==============================] - 98s 616us/sample - loss: 1.1688 - val_loss: 1.1468\n","Epoch 29/50\n","158400/158400 [==============================] - 98s 621us/sample - loss: 1.1582 - val_loss: 1.1090\n","Epoch 30/50\n","158400/158400 [==============================] - 96s 608us/sample - loss: 1.1536 - val_loss: 1.1574\n","Epoch 31/50\n","158400/158400 [==============================] - 97s 610us/sample - loss: 1.1455 - val_loss: 1.1203\n","Epoch 32/50\n","158400/158400 [==============================] - 97s 613us/sample - loss: 1.1353 - val_loss: 1.1219\n","Epoch 33/50\n","158400/158400 [==============================] - 98s 621us/sample - loss: 1.1259 - val_loss: 1.1026\n","Epoch 34/50\n","158400/158400 [==============================] - 97s 613us/sample - loss: 1.1235 - val_loss: 1.1137\n","Epoch 35/50\n","158400/158400 [==============================] - 99s 624us/sample - loss: 1.1180 - val_loss: 1.0781\n","Epoch 36/50\n","158400/158400 [==============================] - 97s 609us/sample - loss: 1.1098 - val_loss: 1.0786\n","Epoch 37/50\n","158400/158400 [==============================] - 99s 628us/sample - loss: 1.0987 - val_loss: 1.0650\n","Epoch 38/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.0908 - val_loss: 1.0632\n","Epoch 39/50\n","158400/158400 [==============================] - 98s 621us/sample - loss: 1.0852 - val_loss: 1.0746\n","Epoch 40/50\n","158400/158400 [==============================] - 100s 628us/sample - loss: 1.0770 - val_loss: 1.0574\n","Epoch 41/50\n","158400/158400 [==============================] - 100s 629us/sample - loss: 1.0671 - val_loss: 1.0549\n","Epoch 42/50\n","158400/158400 [==============================] - 100s 631us/sample - loss: 1.0624 - val_loss: 1.0413\n","Epoch 43/50\n","158400/158400 [==============================] - 99s 626us/sample - loss: 1.0585 - val_loss: 1.0404\n","Epoch 44/50\n","158400/158400 [==============================] - 98s 620us/sample - loss: 1.0451 - val_loss: 1.0274\n","Epoch 45/50\n","158400/158400 [==============================] - 96s 605us/sample - loss: 1.0389 - val_loss: 1.0350\n","Epoch 46/50\n","158400/158400 [==============================] - 97s 615us/sample - loss: 1.0378 - val_loss: 1.0219\n","Epoch 47/50\n","158400/158400 [==============================] - 96s 606us/sample - loss: 1.0270 - val_loss: 1.0404\n","Epoch 48/50\n","158400/158400 [==============================] - 100s 630us/sample - loss: 1.0179 - val_loss: 1.0197\n","Epoch 49/50\n","158400/158400 [==============================] - 100s 629us/sample - loss: 1.0117 - val_loss: 1.0061\n","Epoch 50/50\n","158400/158400 [==============================] - 97s 615us/sample - loss: 1.0085 - val_loss: 1.0158\n","Train on 158400 samples, validate on 17600 samples\n","Epoch 1/50\n","158400/158400 [==============================] - 109s 687us/sample - loss: 2.2207 - val_loss: 1.9477\n","Epoch 2/50\n","158400/158400 [==============================] - 106s 672us/sample - loss: 1.8673 - val_loss: 1.7092\n","Epoch 3/50\n","158400/158400 [==============================] - 107s 676us/sample - loss: 1.6924 - val_loss: 1.5920\n","Epoch 4/50\n","158400/158400 [==============================] - 109s 687us/sample - loss: 1.5693 - val_loss: 1.4247\n","Epoch 5/50\n","158400/158400 [==============================] - 109s 687us/sample - loss: 1.4802 - val_loss: 1.3724\n","Epoch 6/50\n","158400/158400 [==============================] - 109s 686us/sample - loss: 1.4380 - val_loss: 1.3697\n","Epoch 7/50\n","158400/158400 [==============================] - 109s 690us/sample - loss: 1.4023 - val_loss: 1.2986\n","Epoch 8/50\n","158400/158400 [==============================] - 104s 657us/sample - loss: 1.3804 - val_loss: 1.3038\n","Epoch 9/50\n","158400/158400 [==============================] - 106s 666us/sample - loss: 1.3476 - val_loss: 1.2610\n","Epoch 10/50\n","158400/158400 [==============================] - 105s 664us/sample - loss: 1.3343 - val_loss: 1.2699\n","Epoch 11/50\n","158400/158400 [==============================] - 107s 676us/sample - loss: 1.3242 - val_loss: 1.2509\n","Epoch 12/50\n","158400/158400 [==============================] - 105s 662us/sample - loss: 1.3150 - val_loss: 1.2513\n","Epoch 13/50\n","158400/158400 [==============================] - 106s 670us/sample - loss: 1.3005 - val_loss: 1.2349\n","Epoch 14/50\n","158400/158400 [==============================] - 104s 659us/sample - loss: 1.2960 - val_loss: 1.2386\n","Epoch 15/50\n","158400/158400 [==============================] - 103s 650us/sample - loss: 1.2865 - val_loss: 1.2374\n","Epoch 16/50\n","158400/158400 [==============================] - 105s 660us/sample - loss: 1.2869 - val_loss: 1.2329\n","Epoch 17/50\n","158400/158400 [==============================] - 104s 657us/sample - loss: 1.2755 - val_loss: 1.2129\n","Epoch 18/50\n","158400/158400 [==============================] - 103s 652us/sample - loss: 1.2670 - val_loss: 1.2146\n","Epoch 19/50\n","158400/158400 [==============================] - 106s 668us/sample - loss: 1.2665 - val_loss: 1.2162\n","Epoch 20/50\n","158400/158400 [==============================] - 108s 680us/sample - loss: 1.2574 - val_loss: 1.2018\n","Epoch 21/50\n","158400/158400 [==============================] - 108s 681us/sample - loss: 1.2532 - val_loss: 1.2011\n","Epoch 22/50\n","158400/158400 [==============================] - 106s 668us/sample - loss: 1.2428 - val_loss: 1.2103\n","Epoch 23/50\n","158400/158400 [==============================] - 107s 678us/sample - loss: 1.2401 - val_loss: 1.1990\n","Epoch 24/50\n","158400/158400 [==============================] - 104s 658us/sample - loss: 1.2357 - val_loss: 1.1943\n","Epoch 25/50\n","158400/158400 [==============================] - 104s 659us/sample - loss: 1.2307 - val_loss: 1.1939\n","Epoch 26/50\n","158400/158400 [==============================] - 104s 656us/sample - loss: 1.2251 - val_loss: 1.1875\n","Epoch 27/50\n","158400/158400 [==============================] - 105s 660us/sample - loss: 1.2213 - val_loss: 1.1844\n","Epoch 28/50\n","158400/158400 [==============================] - 103s 648us/sample - loss: 1.2214 - val_loss: 1.1875\n","Epoch 29/50\n","158400/158400 [==============================] - 104s 655us/sample - loss: 1.2202 - val_loss: 1.1809\n","Epoch 30/50\n","158400/158400 [==============================] - 102s 645us/sample - loss: 1.2113 - val_loss: 1.1896\n","Epoch 31/50\n","158400/158400 [==============================] - 103s 649us/sample - loss: 1.2071 - val_loss: 1.1860\n","Epoch 32/50\n","158400/158400 [==============================] - 104s 656us/sample - loss: 1.2030 - val_loss: 1.1793\n","Epoch 33/50\n","158400/158400 [==============================] - 102s 646us/sample - loss: 1.2004 - val_loss: 1.1913\n","Epoch 34/50\n","158400/158400 [==============================] - 105s 664us/sample - loss: 1.1942 - val_loss: 1.2043\n","Epoch 35/50\n","158400/158400 [==============================] - 106s 667us/sample - loss: 1.1899 - val_loss: 1.1830\n","Epoch 36/50\n","158400/158400 [==============================] - 105s 661us/sample - loss: 1.1896 - val_loss: 1.1886\n","Epoch 37/50\n","158400/158400 [==============================] - 105s 662us/sample - loss: 1.1837 - val_loss: 1.1911\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n","Traceback (most recent call last):\n","  File \"test_exp_pgd.py\", line 81, in <module>\n","    defense=defense)\n","  File \"/content/gdrive/MyDrive/Git/adversarial-radioml/arml/exp/exp_pgd_impact.py\", line 156, in experiment_pgd\n","    Yhat_deepfool = model.predict(Xdeepfool[snrs_te == snr])\n","NameError: name 'Xdeepfool' is not defined\n"]}],"source":["!python test_exp_pgd.py"],"id":"LHSK1Chx_K_D"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DEAqr-m2Y7r"},"outputs":[],"source":["!python test_exp_single_attack.py FastGradientMethod"],"id":"8DEAqr-m2Y7r"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CHCK6_-C-HCG","outputId":"8ecb41c5-f8b6-44d0-8273-4ba102c18c75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 158400 samples, validate on 17600 samples\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n","Epoch 1/50\n","2022-04-23 02:05:04.182296: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","158400/158400 [==============================] - 146s 925us/sample - loss: 2.2144 - val_loss: 1.9391\n","Epoch 2/50\n","158400/158400 [==============================] - 128s 806us/sample - loss: 1.8863 - val_loss: 1.7466\n","Epoch 3/50\n","158400/158400 [==============================] - 128s 811us/sample - loss: 1.7552 - val_loss: 1.5826\n","Epoch 4/50\n","158400/158400 [==============================] - 126s 795us/sample - loss: 1.6224 - val_loss: 1.5919\n","Epoch 5/50\n","158400/158400 [==============================] - 129s 813us/sample - loss: 1.5641 - val_loss: 1.4080\n","Epoch 6/50\n","158400/158400 [==============================] - 128s 810us/sample - loss: 1.5230 - val_loss: 1.3670\n","Epoch 7/50\n","158400/158400 [==============================] - 127s 803us/sample - loss: 1.4393 - val_loss: 1.3812\n","Epoch 8/50\n","158400/158400 [==============================] - 128s 809us/sample - loss: 1.4096 - val_loss: 1.3609\n","Epoch 9/50\n","158400/158400 [==============================] - 129s 812us/sample - loss: 1.3822 - val_loss: 1.2788\n","Epoch 10/50\n","158400/158400 [==============================] - 128s 808us/sample - loss: 1.3581 - val_loss: 1.2573\n","Epoch 11/50\n","158400/158400 [==============================] - 129s 812us/sample - loss: 1.3369 - val_loss: 1.2338\n","Epoch 12/50\n","158400/158400 [==============================] - 126s 796us/sample - loss: 1.3227 - val_loss: 1.2361\n","Epoch 13/50\n","158400/158400 [==============================] - 129s 813us/sample - loss: 1.3125 - val_loss: 1.2155\n","Epoch 14/50\n","158400/158400 [==============================] - 128s 808us/sample - loss: 1.2880 - val_loss: 1.1983\n","Epoch 15/50\n","158400/158400 [==============================] - 127s 801us/sample - loss: 1.2839 - val_loss: 1.2021\n","Epoch 16/50\n","158400/158400 [==============================] - 126s 797us/sample - loss: 1.2734 - val_loss: 1.2043\n","Epoch 17/50\n","158400/158400 [==============================] - 129s 816us/sample - loss: 1.2645 - val_loss: 1.1746\n","Epoch 18/50\n","158400/158400 [==============================] - 126s 797us/sample - loss: 1.2607 - val_loss: 1.1841\n","Epoch 19/50\n","158400/158400 [==============================] - 129s 813us/sample - loss: 1.2409 - val_loss: 1.1616\n","Epoch 20/50\n","158400/158400 [==============================] - 127s 801us/sample - loss: 1.2349 - val_loss: 1.1670\n","Epoch 21/50\n","158400/158400 [==============================] - 127s 800us/sample - loss: 1.2230 - val_loss: 1.1652\n","Epoch 22/50\n","158400/158400 [==============================] - 128s 808us/sample - loss: 1.2163 - val_loss: 1.1472\n","Epoch 23/50\n","158400/158400 [==============================] - 129s 813us/sample - loss: 1.2116 - val_loss: 1.1382\n","Epoch 24/50\n","158400/158400 [==============================] - 126s 799us/sample - loss: 1.1989 - val_loss: 1.1450\n","Epoch 25/50\n","158400/158400 [==============================] - 129s 812us/sample - loss: 1.1890 - val_loss: 1.1281\n","Epoch 26/50\n","158400/158400 [==============================] - 128s 808us/sample - loss: 1.1778 - val_loss: 1.1239\n","Epoch 27/50\n","158400/158400 [==============================] - 127s 801us/sample - loss: 1.1734 - val_loss: 1.1510\n","Epoch 28/50\n","158400/158400 [==============================] - 128s 808us/sample - loss: 1.1665 - val_loss: 1.1101\n","Epoch 29/50\n","158400/158400 [==============================] - 127s 803us/sample - loss: 1.1579 - val_loss: 1.1286\n","Epoch 30/50\n","158400/158400 [==============================] - 126s 797us/sample - loss: 1.1456 - val_loss: 1.1109\n","Epoch 31/50\n","158400/158400 [==============================] - 129s 814us/sample - loss: 1.1383 - val_loss: 1.0864\n","Epoch 32/50\n","158400/158400 [==============================] - 126s 795us/sample - loss: 1.1352 - val_loss: 1.1039\n","Epoch 33/50\n","158400/158400 [==============================] - 127s 799us/sample - loss: 1.1234 - val_loss: 1.1013\n","Epoch 34/50\n","158400/158400 [==============================] - 128s 808us/sample - loss: 1.1171 - val_loss: 1.0752\n","Epoch 35/50\n","158400/158400 [==============================] - 127s 802us/sample - loss: 1.1080 - val_loss: 1.0762\n","Epoch 36/50\n","158400/158400 [==============================] - 126s 796us/sample - loss: 1.0940 - val_loss: 1.0761\n","Epoch 37/50\n","158400/158400 [==============================] - 127s 801us/sample - loss: 1.0903 - val_loss: 1.0777\n","Epoch 38/50\n","158400/158400 [==============================] - 128s 810us/sample - loss: 1.0824 - val_loss: 1.0678\n","Epoch 39/50\n","158400/158400 [==============================] - 129s 813us/sample - loss: 1.0772 - val_loss: 1.0654\n","Epoch 40/50\n","158400/158400 [==============================] - 126s 798us/sample - loss: 1.0605 - val_loss: 1.0759\n","Epoch 41/50\n","158400/158400 [==============================] - 129s 812us/sample - loss: 1.0552 - val_loss: 1.0342\n","Epoch 42/50\n","158400/158400 [==============================] - 128s 809us/sample - loss: 1.0460 - val_loss: 1.0326\n","Epoch 43/50\n","158400/158400 [==============================] - 129s 811us/sample - loss: 1.0365 - val_loss: 1.0243\n","Epoch 44/50\n","158400/158400 [==============================] - 128s 807us/sample - loss: 1.0310 - val_loss: 1.0180\n","Epoch 45/50\n","158400/158400 [==============================] - 127s 801us/sample - loss: 1.0236 - val_loss: 1.0189\n","Epoch 46/50\n","158400/158400 [==============================] - 126s 797us/sample - loss: 1.0156 - val_loss: 1.0192\n","Epoch 47/50\n","158400/158400 [==============================] - 129s 812us/sample - loss: 1.0066 - val_loss: 1.0129\n","Epoch 48/50\n","158400/158400 [==============================] - 128s 810us/sample - loss: 1.0003 - val_loss: 0.9940\n","Epoch 49/50\n","158400/158400 [==============================] - 129s 812us/sample - loss: 0.9902 - val_loss: 0.9865\n","Epoch 50/50\n","158400/158400 [==============================] - 126s 797us/sample - loss: 0.9880 - val_loss: 0.9917\n","Train on 158400 samples, validate on 17600 samples\n","Epoch 1/50\n","158400/158400 [==============================] - 140s 881us/sample - loss: 2.3971 - val_loss: 2.3936\n","Epoch 2/50\n","158400/158400 [==============================] - 137s 868us/sample - loss: 2.1361 - val_loss: 1.9993\n","Epoch 3/50\n","158400/158400 [==============================] - 136s 861us/sample - loss: 1.8485 - val_loss: 1.6305\n","Epoch 4/50\n","158400/158400 [==============================] - 136s 860us/sample - loss: 1.6200 - val_loss: 1.4964\n","Epoch 5/50\n","158400/158400 [==============================] - 137s 864us/sample - loss: 1.5180 - val_loss: 1.3937\n","Epoch 6/50\n","158400/158400 [==============================] - 136s 862us/sample - loss: 1.4609 - val_loss: 1.3935\n","Epoch 7/50\n","158400/158400 [==============================] - 136s 860us/sample - loss: 1.4271 - val_loss: 1.3354\n","Epoch 8/50\n","158400/158400 [==============================] - 137s 862us/sample - loss: 1.4012 - val_loss: 1.2988\n","Epoch 9/50\n","158400/158400 [==============================] - 137s 862us/sample - loss: 1.3766 - val_loss: 1.2880\n","Epoch 10/50\n","158400/158400 [==============================] - 135s 849us/sample - loss: 1.3563 - val_loss: 1.2903\n","Epoch 11/50\n","158400/158400 [==============================] - 136s 861us/sample - loss: 1.3423 - val_loss: 1.2729\n","Epoch 12/50\n","158400/158400 [==============================] - 134s 849us/sample - loss: 1.3290 - val_loss: 1.2892\n","Epoch 13/50\n","158400/158400 [==============================] - 135s 850us/sample - loss: 1.3215 - val_loss: 1.2881\n","Epoch 14/50\n","158400/158400 [==============================] - 137s 863us/sample - loss: 1.3065 - val_loss: 1.2536\n","Epoch 15/50\n","158400/158400 [==============================] - 136s 861us/sample - loss: 1.3012 - val_loss: 1.2458\n","Epoch 16/50\n","158400/158400 [==============================] - 137s 862us/sample - loss: 1.2944 - val_loss: 1.2350\n","Epoch 17/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.2962 - val_loss: 1.2380\n","Epoch 18/50\n","158400/158400 [==============================] - 137s 863us/sample - loss: 1.2792 - val_loss: 1.2270\n","Epoch 19/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.2727 - val_loss: 1.2702\n","Epoch 20/50\n","158400/158400 [==============================] - 137s 867us/sample - loss: 1.2712 - val_loss: 1.2174\n","Epoch 21/50\n","158400/158400 [==============================] - 134s 848us/sample - loss: 1.2641 - val_loss: 1.2216\n","Epoch 22/50\n","158400/158400 [==============================] - 135s 852us/sample - loss: 1.2624 - val_loss: 1.2426\n","Epoch 23/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.2565 - val_loss: 1.2188\n","Epoch 24/50\n","158400/158400 [==============================] - 137s 866us/sample - loss: 1.2485 - val_loss: 1.2131\n","Epoch 25/50\n","158400/158400 [==============================] - 137s 862us/sample - loss: 1.2440 - val_loss: 1.2090\n","Epoch 26/50\n","158400/158400 [==============================] - 137s 863us/sample - loss: 1.2413 - val_loss: 1.2052\n","Epoch 27/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.2311 - val_loss: 1.2056\n","Epoch 28/50\n","158400/158400 [==============================] - 135s 850us/sample - loss: 1.2345 - val_loss: 1.2214\n","Epoch 29/50\n","158400/158400 [==============================] - 136s 858us/sample - loss: 1.2291 - val_loss: 1.1970\n","Epoch 30/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.2314 - val_loss: 1.2261\n","Epoch 31/50\n","158400/158400 [==============================] - 135s 849us/sample - loss: 1.2264 - val_loss: 1.1989\n","Epoch 32/50\n","158400/158400 [==============================] - 135s 852us/sample - loss: 1.2220 - val_loss: 1.2051\n","Epoch 33/50\n","158400/158400 [==============================] - 134s 848us/sample - loss: 1.2167 - val_loss: 1.2272\n","Epoch 34/50\n","158400/158400 [==============================] - 136s 856us/sample - loss: 1.2140 - val_loss: 1.1857\n","Epoch 35/50\n","158400/158400 [==============================] - 134s 848us/sample - loss: 1.2091 - val_loss: 1.1876\n","Epoch 36/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.2027 - val_loss: 1.1873\n","Epoch 37/50\n","158400/158400 [==============================] - 135s 852us/sample - loss: 1.2021 - val_loss: 1.1950\n","Epoch 38/50\n","158400/158400 [==============================] - 135s 850us/sample - loss: 1.1988 - val_loss: 1.1981\n","Epoch 39/50\n","158400/158400 [==============================] - 135s 851us/sample - loss: 1.1969 - val_loss: 1.1879\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]}],"source":["!python test_exp_single_attack.py DeepFool"],"id":"CHCK6_-C-HCG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZUgcb8jUGzA"},"outputs":[],"source":["!python test_exp_single_attack.py ProjectedGradientDescent"],"id":"oZUgcb8jUGzA"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"colab-arml-main.ipynb","provenance":[]},"interpreter":{"hash":"0fd9392274fc82a63c2a75f43f796d95e051853c3a46ffe4696bb4291dc65e3b"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}